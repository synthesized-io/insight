{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Space Stability\n",
    "---\n",
    "This notebook explores the stability of the Latent Space in the HighDimSynthesizer for various datasets.\n",
    "\n",
    "Below we use the **synthesized.insight** module to work with a dataset's latent space. There are three utility functions used for fetching information about the latent space of a dataset. Each one listed below returns a more compact summary that the one above.\n",
    "- `get_latent_space()`: returns the entire dataset encoded into the latent_space. \n",
    "    - The columns in the returned dataframe are l_0, ..., l_N-1, m_0, ..., m_N-1, s_0, ..., s_N-1. \n",
    "    - m_i is the encoded mean value for dimension i and each row, \n",
    "    - s_i is the encoded stddev for each dimension i and each row, \n",
    "    - and l_i is a sample from the encoded distribution in each dimension i and each row.\n",
    "    - **returns a (num_rows, 3xnum_latent_dimensions) array as a DataFrame.**\n",
    "- `latent_dimennsion_usage()`: returns the 'usage' of each dimension for the dataset (typically usage should be between 0 and 1). \n",
    "    - Note there are two ways to calculate this (see further down for details).\n",
    "    - **returns a (num_latent_dimensions, 1) array as a DataFrame.**\n",
    "- `total_latent_space_usage()`\n",
    "    - **returns a scalar value reflecting the total latent space usage.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from typing import List\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings(action='ignore', module='numpy')\n",
    "warnings.filterwarnings(action='ignore', module='pandas')\n",
    "warnings.filterwarnings(action='ignore', module='sklearn')\n",
    "warnings.filterwarnings(action='ignore', module='tensorflow')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from synthesized import HighDimSynthesizer\n",
    "from synthesized.common import ValueFactory\n",
    "from synthesized.insight.latent import get_latent_space, latent_dimension_usage, total_latent_space_usage\n",
    "from synthesized.insight.dataset import describe_dataset_values, describe_dataset, classification_score\n",
    "\n",
    "\n",
    "if not 'workbookDir' in globals():\n",
    "    workbookDir = os.getcwd()\n",
    "os.chdir(os.path.split(os.path.split(workbookDir)[0])[0])\n",
    "\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.max_columns = 50\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas = pd.read_csv('data/templates/atlas_higgs_detection.csv')\n",
    "credit = pd.read_csv('data/templates/credit.csv')\n",
    "insure = pd.read_csv('data/templates/claim_prediction.csv')\n",
    "telecom = pd.read_csv('data/templates/telecom-churn.csv')\n",
    "\n",
    "DATASETS = {'atlas': atlas, 'credit': credit, 'insure': insure, 'telecom': telecom}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_CategoricalValue</th>\n",
       "      <th>num_ContinuousValue</th>\n",
       "      <th>num_NanValue</th>\n",
       "      <th>num_SamplingValue</th>\n",
       "      <th>total_columns</th>\n",
       "      <th>total_rows</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>atlas</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insure</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>telecom</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>7043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         num_CategoricalValue  num_ContinuousValue  num_NanValue  \\\n",
       "dataset                                                            \n",
       "atlas                       2                   31           NaN   \n",
       "credit                      6                    5           1.0   \n",
       "insure                      5                    3           NaN   \n",
       "telecom                    17                    3           1.0   \n",
       "\n",
       "         num_SamplingValue  total_columns  total_rows  \n",
       "dataset                                                \n",
       "atlas                  NaN             33      100000  \n",
       "credit                 NaN             11      150000  \n",
       "insure                 NaN              8        1338  \n",
       "telecom                1.0             21        7043  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([describe_dataset(ds).set_index('property').T.rename(index=lambda x: name) for name, ds in DATASETS.items()], axis='index', sort=True).rename_axis('dataset', axis='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stability Experiments\n",
    "---\n",
    "Considering the stability in the latent space:\n",
    "- Variables:\n",
    "    - dataset\n",
    "    - number of training iterations\n",
    "    - number of rows (same sample)\n",
    "    - number of rows (different samples)\n",
    "    - latent space usage type\n",
    "        - \"stddev\": we can measure latent space usage in each dimension by considering the average 'stddev' for the dataset, $\\sigma\\text{-LSU}_n$.\n",
    "        - \"mean\": or we can measure the usage by considering the standard deviation of the 'mean' for the dataset, $\\mu\\text{-LSU}_n$.\n",
    "        \n",
    "$\\sigma\\text{-LSU}_n = 1-\\text{AVE}(\\sigma_{n,i})$ \n",
    "\n",
    "$\\mu\\text{-LSU}_n = \\sqrt{\\text{VAR}(\\mu_{n,i})}$\n",
    "\n",
    "Where $n$ is the dimension and i corresponds to the row-$i$. The average and variance functions are performed over the rows, $i$. \n",
    "\n",
    "0 = unused, 1 = used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ITERATIONS = [5000]\n",
    "NUM_ROWS = [128, 256, 512, 1024]\n",
    "REPEATS = 3\n",
    "LSU_TYPES = ['stddev', 'mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 1:  Same Subsample Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1618033\n",
    "experiment_1_trials = []\n",
    "\n",
    "for name, ds in DATASETS.items():\n",
    "    for num_iter in NUM_ITERATIONS:\n",
    "        for num_rows in NUM_ROWS:\n",
    "            for trial in range(REPEATS):\n",
    "                \n",
    "                latent_space = get_latent_space(df=ds.sample(num_rows, random_state=random_seed), num_iterations=num_iter)\n",
    "                \n",
    "                for usage_type in LSU_TYPES:\n",
    "                    lsu = latent_dimension_usage(df_latent=latent_space, usage_type=usage_type)\n",
    "                    lsu = lsu.drop('dimension', axis='columns').T.rename(columns=lambda x: f'z{x}').reset_index(drop=True)\n",
    "                    \n",
    "                    df_params = pd.DataFrame.from_records([{\n",
    "                        'lsu_type': usage_type, 'dataset': name, 'num_iterations': num_iter, \n",
    "                        'num_rows': num_rows, 'trial': trial\n",
    "                    }])\n",
    "                    \n",
    "                    df_trial = pd.concat((df_params, lsu), axis='columns')\n",
    "                    experiment_1_trials.append(df_trial)\n",
    "\n",
    "experiment_1_trials = pd.concat(experiment_1_trials, axis='index', ignore_index=True)\n",
    "experiment_1_data = experiment_1_trials.melt(id_vars=['lsu_type', 'dataset', 'num_iterations', 'num_rows', 'trial'], var_name='latent_dim', value_name='usage')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(\n",
    "    data=experiment_1_data, x='num_rows', y='usage', hue='latent_dim', row='dataset', col='lsu_type',\n",
    "    kind='bar', aspect=2.2, legend=None, palette=sns.light_palette((230, 90, 60), input=\"husl\", n_colors=32, reverse=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=experiment_1_data, x='num_rows', y='usage', hue='latent_dim', row='dataset', col='lsu_type',\n",
    "    kind='line', aspect=2.2, legend=None, palette=sns.light_palette(\"navy\", reverse=True, n_colors=32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 2: Random Subsample Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_2_trials = []\n",
    "\n",
    "for name, ds in DATASETS.items():\n",
    "    for num_iter in NUM_ITERATIONS:\n",
    "        for num_rows in NUM_ROWS:\n",
    "            for trial in range(REPEATS):\n",
    "                \n",
    "                latent_space = get_latent_space(df=ds.sample(num_rows, random_state=trial), num_iterations=num_iter)\n",
    "                \n",
    "                for usage_type in LSU_TYPES:\n",
    "                    lsu = latent_dimension_usage(df_latent=latent_space, usage_type=usage_type)\n",
    "                    lsu = lsu.drop('dimension', axis='columns').T.reset_index(drop=True)\n",
    "                    \n",
    "                    df_params = pd.DataFrame.from_records([{\n",
    "                        'lsu_type': usage_type, 'dataset': name, 'num_iterations': num_iter, \n",
    "                        'num_rows': num_rows, 'trial': trial\n",
    "                    }])\n",
    "                    \n",
    "                    df_trial = pd.concat((df_params, lsu), axis='columns')\n",
    "                    experiment_2_trials.append(df_trial)\n",
    "\n",
    "experiment_2_trials = pd.concat(experiment_2_trials, axis='index', ignore_index=True)\n",
    "experiment_2_data = experiment_2_trials.melt(id_vars=['lsu_type', 'dataset', 'num_iterations', 'num_rows', 'trial'], var_name='latent_dim', value_name='usage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synthesized",
   "language": "python",
   "name": "synthesized"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
