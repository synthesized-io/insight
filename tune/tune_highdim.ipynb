{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import ax\n",
    "import pandas as pd\n",
    "import ray\n",
    "from ax.service.ax_client import AxClient\n",
    "from ax.plot.contour import interact_contour, plot_contour\n",
    "from ax.plot.slice import plot_slice\n",
    "from ax.utils.notebook.plotting import render, init_notebook_plotting\n",
    "from ax.service.utils.best_point import get_best_from_model_predictions, get_best_raw_objective_point\n",
    "from ray import tune\n",
    "from ray.tune import track, JupyterNotebookReporter\n",
    "from ray.tune.suggest.ax import AxSearch\n",
    "from ray.tune.suggest.suggestion import SuggestionAlgorithm\n",
    "from ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n",
    "from ax.modelbridge.registry import Models\n",
    "\n",
    "from synthesized import HighDimSynthesizer\n",
    "\n",
    "\n",
    "root_logger = logging.getLogger()\n",
    "root_logger.setLevel(50)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def train_evaluate(parameterization):\n",
    "    with HighDimSynthesizer(df=data, **parameterization) as synthesizer:     \n",
    "        synthesizer.learn(data, num_iterations=None)\n",
    "        \n",
    "        data_ = synthesizer.preprocess(data.sample(loss_sample_size))\n",
    "        feed_dict = synthesizer.get_data_feed_dict(data_)\n",
    "        losses = synthesizer.get_losses(data=feed_dict)\n",
    "        \n",
    "        loss = losses['total-loss'].numpy().item()\n",
    "\n",
    "        track.log(\n",
    "            mean_loss=loss,\n",
    "            reconstruction_loss = losses['reconstruction-loss'].numpy().item(),\n",
    "            kl_loss = losses['kl-loss'].numpy().item()\n",
    "        )\n",
    "\n",
    "class AxSearch2(SuggestionAlgorithm):\n",
    "    \"\"\"A wrapper around Ax to provide trial suggestions.\"\"\"\n",
    "\n",
    "    def __init__(self, ax_client, max_concurrent=10, standard_error=0.05, **kwargs):\n",
    "        assert ax is not None, \"Ax must be installed!\"\n",
    "        assert type(max_concurrent) is int and max_concurrent > 0\n",
    "        self._ax = ax_client\n",
    "        exp = self._ax.experiment\n",
    "        self._objective_name = exp.optimization_config.objective.metric.name\n",
    "        if self._ax._enforce_sequential_optimization:\n",
    "            logger.warning(\"Detected sequential enforcement. Setting max \"\n",
    "                           \"concurrency to 1.\")\n",
    "            max_concurrent = 1\n",
    "        self._max_concurrent = max_concurrent\n",
    "        self._parameters = list(exp.parameters)\n",
    "        self._live_index_mapping = {}\n",
    "        self._standard_error = standard_error\n",
    "        self._num_completed = 0\n",
    "        super(AxSearch2, self).__init__(**kwargs)\n",
    "\n",
    "    def _suggest(self, trial_id):\n",
    "        if self._num_live_trials() >= self._max_concurrent:\n",
    "            return None\n",
    "        parameters, trial_index = self._ax.get_next_trial()\n",
    "        self._live_index_mapping[trial_id] = trial_index\n",
    "        \n",
    "        return parameters\n",
    "\n",
    "    def on_trial_result(self, trial_id, result):\n",
    "        pass\n",
    "\n",
    "    def on_trial_complete(self,\n",
    "                          trial_id,\n",
    "                          result=None,\n",
    "                          error=False,\n",
    "                          early_terminated=False):\n",
    "        \"\"\"Notification for the completion of trial.\n",
    "\n",
    "        Data of form key value dictionary of metric names and values.\n",
    "        \"\"\"\n",
    "        if result:\n",
    "            self._process_result(trial_id, result, early_terminated)\n",
    "        self._live_index_mapping.pop(trial_id)\n",
    "\n",
    "    def _process_result(self, trial_id, result, early_terminated=False):\n",
    "        if early_terminated and self._use_early_stopped is False:\n",
    "            return\n",
    "        ax_trial_index = self._live_index_mapping[trial_id]\n",
    "        metric_dict = {\n",
    "            self._objective_name: (result[self._objective_name], self._standard_error*result[self._objective_name])\n",
    "        }\n",
    "        outcome_names = [\n",
    "            oc.metric.name for oc in\n",
    "            self._ax.experiment.optimization_config.outcome_constraints\n",
    "        ]\n",
    "        metric_dict.update({on: (result[on], self._standard_error*result[on]) for on in outcome_names})\n",
    "        self._ax.complete_trial(\n",
    "            trial_index=ax_trial_index, raw_data=metric_dict)\n",
    "\n",
    "    def _num_live_trials(self):\n",
    "        return len(self._live_index_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_notebook_plotting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init(address='auto', redis_password='5241590000000000', log_to_driver=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GenerationStrategy(\n",
    "    steps=[\n",
    "        GenerationStep(\n",
    "            model=Models.SOBOL,\n",
    "            num_arms=25, \n",
    "            min_arms_observed=5, \n",
    "            recommended_max_parallelism=5, \n",
    "            enforce_num_arms=False, \n",
    "            model_kwargs={'deduplicate': True, 'seed': None},\n",
    "            model_gen_kwargs=None\n",
    "        ),\n",
    "         GenerationStep(\n",
    "            model=Models.GPEI,\n",
    "            num_arms=-1,\n",
    "            min_arms_observed=0,\n",
    "            recommended_max_parallelism=20,\n",
    "            enforce_num_arms=True, \n",
    "            model_kwargs=None, \n",
    "            model_gen_kwargs=None,\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_sample_size = 50_000\n",
    "data = pd.read_csv('data/credit_with_categoricals.csv')\n",
    "data = data.dropna()\n",
    "loss_sample_size = min(loss_sample_size, len(data))\n",
    "\n",
    "axc = AxClient(generation_strategy=gs, verbose_logging=False, enforce_sequential_optimization=False)\n",
    "axc.create_experiment(\n",
    "    name=\"capacity_tuning\",\n",
    "    parameters=[\n",
    "        {\"name\": \"capacity\", \"type\": \"range\", \"bounds\": [8, 128]},\n",
    "        {\"name\": \"latent_size\", \"type\": \"range\", \"bounds\": [8, 128]},\n",
    "        {\"name\": \"num_layers\", \"type\": \"range\", \"bounds\": [1, 4]},\n",
    "        {\"name\": \"residual_depths\", \"type\": \"range\", \"bounds\": [2, 6]},\n",
    "        {\"name\": \"learning_rate\", \"type\": \"range\", \"bounds\": [1e-5, 1e-1], \"log_scale\": True},\n",
    "        {\"name\": \"max_training_time\", \"type\": \"fixed\", \"value\": 120.0}\n",
    "    ],\n",
    "    objective_name=\"mean_loss\",\n",
    "    minimize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "    train_evaluate,\n",
    "    num_samples=100,\n",
    "    search_alg=AxSearch2(axc, max_concurrent=20),  # Note that the argument here is the `AxClient`.\n",
    "    verbose=1,  # Set this level to 1 to see status updates and to 2 to also see trial results.\n",
    "    # To use GPU, specify: resources_per_trial={\"gpu\": 1}.\n",
    "    resources_per_trial={\"cpu\": 2},\n",
    "    max_failures=3,\n",
    "    progress_reporter=JupyterNotebookReporter(overwrite=True, max_progress_rows=100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the best parameters from comparing all trials\n",
    "params, mean_value = get_best_raw_objective_point(axc.experiment)\n",
    "print(\"Best Trial Params:\")\n",
    "print(params, mean_value)\n",
    "\n",
    "# Gets the parameters by predicting with the bayesian model\n",
    "params, (mean_value, variance) = get_best_from_model_predictions(axc.experiment)\n",
    "print(\"Estimated Best Params:\")\n",
    "print(params, mean_value, variance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render(axc.get_feature_importances())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in params:\n",
    "    try:\n",
    "        render(plot_slice(axc.generation_strategy.model, param, 'mean_loss'))\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render(interact_contour(axc.generation_strategy.model, metric_name='mean_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render(axc.get_optimization_trace())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axc.get_trials_data_frame()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
