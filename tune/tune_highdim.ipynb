{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import ax\n",
    "import pandas as pd\n",
    "import ray\n",
    "from ax.service.ax_client import AxClient\n",
    "from ax.plot.contour import interact_contour, plot_contour\n",
    "from ax.plot.slice import plot_slice\n",
    "from ax.utils.notebook.plotting import render, init_notebook_plotting\n",
    "from ax.service.utils.best_point import get_best_from_model_predictions, get_best_raw_objective_point\n",
    "from ray import tune\n",
    "from ray.tune import track, JupyterNotebookReporter\n",
    "from ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n",
    "from ax.modelbridge.registry import Models\n",
    "\n",
    "from synthesized import HighDimSynthesizer\n",
    "from tune_utils import AxSearch2\n",
    "\n",
    "\n",
    "root_logger = logging.getLogger()\n",
    "root_logger.setLevel(50)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def ray_callback(synthesizer, iteration, losses):\n",
    "    track.log(\n",
    "        iteration = iteration\n",
    "    )\n",
    "    return False\n",
    "\n",
    "\n",
    "def train_evaluate(parameterization):\n",
    "    with HighDimSynthesizer(df=data, **parameterization) as synthesizer:     \n",
    "        synthesizer.learn(data, num_iterations=None, callback=ray_callback, callback_freq=1)\n",
    "        \n",
    "        data_ = synthesizer.preprocess(data.sample(loss_sample_size))\n",
    "        feed_dict = synthesizer.get_data_feed_dict(data_)\n",
    "        losses = synthesizer.get_losses(data=feed_dict)\n",
    "        \n",
    "        loss = losses['total-loss'].numpy().item()\n",
    "\n",
    "        track.log(\n",
    "            mean_loss=loss,\n",
    "            reconstruction_loss = losses['reconstruction-loss'].numpy().item(),\n",
    "            kl_loss = losses['kl-loss'].numpy().item(),\n",
    "            iteration = synthesizer.global_step.numpy().item()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_notebook_plotting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init(address='auto', redis_password='5241590000000000', log_to_driver=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GenerationStrategy(\n",
    "    steps=[\n",
    "        GenerationStep(\n",
    "            model=Models.SOBOL,\n",
    "            num_trials=20, \n",
    "            min_trials_observed=15, \n",
    "            max_parallelism=20, \n",
    "            enforce_num_trials=True, \n",
    "            model_kwargs={'deduplicate': True, 'seed': None},\n",
    "            model_gen_kwargs=None\n",
    "        ),\n",
    "         GenerationStep(\n",
    "            model=Models.GPEI,\n",
    "            num_trials=-1,\n",
    "            min_trials_observed=0,\n",
    "            max_parallelism=20,\n",
    "            enforce_num_trials=True, \n",
    "            model_kwargs=None, \n",
    "            model_gen_kwargs=None,\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "axc = AxClient(generation_strategy=gs, verbose_logging=False, enforce_sequential_optimization=False)\n",
    "axc.create_experiment(\n",
    "    name=\"capacity_tuning\",\n",
    "    parameters=[\n",
    "        {\"name\": \"capacity\", \"type\": \"range\", \"bounds\": [8, 128]},\n",
    "        {\"name\": \"latent_size\", \"type\": \"range\", \"bounds\": [8, 128]},\n",
    "        {\"name\": \"num_layers\", \"type\": \"range\", \"bounds\": [1, 4]},\n",
    "        {\"name\": \"residual_depths\", \"type\": \"range\", \"bounds\": [2, 6]},\n",
    "        {\"name\": \"learning_rate\", \"type\": \"range\", \"bounds\": [1e-5, 1e-1], \"log_scale\": True},\n",
    "        {\"name\": \"max_training_time\", \"type\": \"fixed\", \"value\": 120.0}\n",
    "    ],\n",
    "    objective_name=\"mean_loss\",\n",
    "    minimize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_sample_size = 50_000\n",
    "data = pd.read_csv('data/credit_with_categoricals.csv')\n",
    "data = data.dropna()\n",
    "loss_sample_size = min(loss_sample_size, len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "    train_evaluate,\n",
    "    num_samples=100,\n",
    "    search_alg=AxSearch2(axc, mode='min'),  # Note that the argument here is the `AxClient`.\n",
    "    verbose=1,  # Set this level to 1 to see status updates and to 2 to also see trial results.\n",
    "    # To use GPU, specify: resources_per_trial={\"gpu\": 1}.\n",
    "    resources_per_trial={\"cpu\": 2},\n",
    "    max_failures=3,\n",
    "    progress_reporter=JupyterNotebookReporter(overwrite=True, max_progress_rows=100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the best parameters from comparing all trials\n",
    "params, mean_value = get_best_raw_objective_point(axc.experiment)\n",
    "print(\"Best Trial Params:\")\n",
    "print(params, mean_value)\n",
    "\n",
    "# Gets the parameters by predicting with the bayesian model\n",
    "params, (mean_value, variance) = get_best_from_model_predictions(axc.experiment)\n",
    "print(\"Estimated Best Params:\")\n",
    "print(params, mean_value, variance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render(axc.get_feature_importances())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in params:\n",
    "    try:\n",
    "        render(plot_slice(axc.generation_strategy.model, param, 'mean_loss'))\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render(interact_contour(axc.generation_strategy.model, metric_name='mean_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render(axc.get_optimization_trace())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axc.get_trials_data_frame()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
