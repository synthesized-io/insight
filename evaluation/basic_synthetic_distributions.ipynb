{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore', message='numpy.dtype size changed')\n",
    "warnings.filterwarnings(action='ignore', message='compiletime version 3.5 of module')\n",
    "\n",
    "if not 'workbookDir' in globals():\n",
    "    workbookDir = os.getcwd()\n",
    "os.chdir(os.path.split(workbookDir)[0])\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copyright (C) Synthesized Ltd. - All Rights Reserved\n",
      "License key: EE6B-6720-67A2-32F3-3139-2D31-322D-B531\n",
      "Expires at: 2019-12-31 00:00:00\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "from synthesized.testing.synthetic_distributions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_values(synthesizer):\n",
    "    print(' ', 'value types:')\n",
    "    for value in synthesizer.values:\n",
    "        print(' ', value.name, value)\n",
    "    print()\n",
    "\n",
    "def log_distance(data, synthesized):\n",
    "    distance = ks_2samp(data['x'], synthesized['x'])[0]\n",
    "    print(' ', 'distance:', distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize(data, num_iterations, num_logging, fn_logging=log_distance, **kwargs):\n",
    "    start = time.time()\n",
    "    with BasicSynthesizer(data, **kwargs) as synthesizer:\n",
    "        log_values(synthesizer)\n",
    "        synthesized = synthesizer.synthesize(n=len(data))\n",
    "        fn_logging(data, synthesized)\n",
    "        for _ in range(num_iterations // num_logging):\n",
    "            synthesizer.learn(data=data, num_iterations=num_logging)\n",
    "            synthesized = synthesizer.synthesize(n=len(data))\n",
    "            fn_logging(data, synthesized)\n",
    "        print()\n",
    "        print(' ', 'took', time.time() - start, 's')\n",
    "        return synthesizer.synthesize(n=len(data))\n",
    "\n",
    "def plot():\n",
    "    value_types = {value.name: type(value) for value in synthesizer.values}\n",
    "    distances = [ks_2samp(data[col], synthesized[col])[0] for col in data.columns]\n",
    "    avg_distance = np.mean(distances)\n",
    "    evaluation[name + '_avg_distance'] = avg_distance\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5), sharex=True, sharey=True)\n",
    "    ax1.set_title('original')\n",
    "    ax2.set_title('synthesized')\n",
    "    _plot_data(data, ax=ax1, value_types=value_types)\n",
    "    _plot_data(synthesized, ax=ax2, value_types=value_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 10000\n",
    "def fn_logging(data, synthesized):\n",
    "    distance = ks_2samp(data['x'], synthesized['x']).statistic\n",
    "    suffix = ''\n",
    "    if distance < 0.05:\n",
    "        suffix += '*'\n",
    "    if distance < 0.01:\n",
    "        suffix += '*'\n",
    "    print('  {:.3f}{}'.format(distance, suffix), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/alexkuhnle/PycharmProjects/synthesized/venv/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/alexkuhnle/PycharmProjects/synthesized/venv/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/alexkuhnle/PycharmProjects/synthesized/venv/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "  value types:\n",
      "  x categorical2-281\n",
      "\n",
      "  0.456   0.322   0.227   0.164   0.110   0.079   0.060   0.048*   0.037*   0.031*   0.025*   0.016*   0.018*   0.015*   0.008**   0.012*   0.009**   0.009**   0.006**   0.010*   0.006**   0.003**   0.006**   0.006**   0.006**   0.009**   0.012*   0.004**   0.000**   0.002**   0.004**   0.002**   0.007**   0.001**   0.003**   0.001**   0.002**   0.003**   0.002**   0.000**   0.001**   0.003**   0.002**   0.001**   0.001**   0.004**   0.004**   0.003**   0.003**   0.000**   0.001** \n",
      "  took 28.573664665222168 s\n"
     ]
    }
   ],
   "source": [
    "data = create_bernoulli(probability=0.1, size=size)\n",
    "synthesized = synthesize(\n",
    "    data=data, summarizer=True, num_iterations=1000, num_logging=20, fn_logging=fn_logging,\n",
    "    # encoder/decoder\n",
    "    network_type='mlp', capacity=512, depth=2, layer_type='dense',\n",
    "    batchnorm=True, activation='relu', weight_decay=1e-3,\n",
    "    # encoding\n",
    "    encoding_type='variational', encoding_size=512, encoding_kwargs=dict(beta=5.0),\n",
    "    # optimizer\n",
    "    optimizer='adam', learning_rate=1e-5, decay_steps=200, decay_rate=0.5,\n",
    "    clip_gradients=1.0, batch_size=128,\n",
    "    # categorical\n",
    "    smoothing=0.0, moving_average=True, similarity_regularization=0.0,\n",
    "    entropy_regularization=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  value types:\n",
      "  x categorical5-458\n",
      "\n",
      "  0.449   0.400   0.336   0.266   0.211   0.163   0.125   0.091   0.080   0.070   0.061   0.056   0.049*   0.049*   0.041*   0.041*   0.035*   0.032*   0.023*   0.030*   0.017*   0.018*   0.020*   0.018*   0.012*   0.011*   0.012*   0.007**   0.010*   0.010*   0.008**   0.014*   0.009**   0.009**   0.014*   0.016*   0.017*   0.014*   0.015*   0.017*   0.022*   0.016*   0.022*   0.023*   0.016*   0.023*   0.014*   0.014*   0.015*   0.019*   0.020* \n",
      "  took 30.78738307952881 s\n"
     ]
    }
   ],
   "source": [
    "data = create_categorical(probabilities=[0.5, 0.25, 0.125, 0.0625, 0.0625], size=size)\n",
    "synthesized = synthesize(\n",
    "    data=data, summarizer=True, num_iterations=1000, num_logging=20, fn_logging=fn_logging,\n",
    "    # encoder/decoder\n",
    "    network_type='mlp', capacity=512, depth=2, layer_type='dense',\n",
    "    batchnorm=True, activation='relu', weight_decay=1e-3,\n",
    "    # encoding\n",
    "    encoding_type='variational', encoding_size=512, encoding_kwargs=dict(beta=5.0),\n",
    "    # optimizer\n",
    "    optimizer='adam', learning_rate=1e-5, decay_steps=200, decay_rate=0.5,\n",
    "    clip_gradients=1.0, batch_size=128,\n",
    "    # categorical\n",
    "    smoothing=0.0, moving_average=True, similarity_regularization=0.0,\n",
    "    entropy_regularization=0.16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### 1-d Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = create_1d_gaussian(mean=1000,  std=100, size=10000)\n",
    "synthesize_and_plot(data, name='1d_gaussian', evaluation=evaluation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
